# The Generate Pipeline

```{r echo=FALSE}
set.seed(22)
```

## Generating Stimuli

One of the most noteworthy features of LexOPS is that it can generate controlled stimuli for any possible factorial design. This can be done in a pipeline using 3 main functions:

<br>
```{block, type='float-third-left'}
`split_by()`

to specify "splits" (independent variables) in the experimental design
```

```{block, type='float-third-centre'}
`control_for()`

to specify variables that should be controlled for between conditions
```

```{block, type='float-third-right'}
`generate()`

to run the algorithm and generate the stimuli, using specified splits and controls
```
<br>

### A Practical Example {-}

Imagine we want to generate stimuli for a 2x2 factorial design in a Lexical Decision Task, examining whether a possible effect of bigram probability interacts with concreteness.

For this, we might decide we want a stimulus set with the following features:

* Filtered such that **at least 90% of people know each word**, according to `r LexOPS::var_to_source("PK.Brysbaert")`.

* **Two levels of Concreteness** (abstract and concrete words) according to `r LexOPS::var_to_source("CNC.Brysbaert")`.

* **Two levels of Bigram Probability** (high and low probability) based on `r LexOPS::var_to_source("BG.SUBTLEX_UK")`.
  
* **Controlled for word length** (number of characters) exactly.

* **Controlled for word frequency** within ±0.2 Zipf, according to according to `r LexOPS::var_to_source("Zipf.SUBTLEX_UK")`.

* **25 words for each of the generated conditions** (100 stimuli in total).

<br>
We can use the following R code to generate a stimulus list like this with LexOPS:

```{r, message=FALSE, results='hide'}
library(LexOPS)

stim <- lexops %>%
  subset(PK.Brysbaert >= 0.9) %>%
  split_by(CNC.Brysbaert, 1:2 ~ 4:5) %>%
  split_by(BG.SUBTLEX_UK, 0:0.003 ~ 0.009:0.013) %>%
  control_for(Length, 0:0) %>%
  control_for(Zipf.SUBTLEX_UK, -0.2:0.2) %>%
  generate(n = 25)
```

<br>
```{block, type="info"}
Important notes on LexOPS (non-standard) syntax:

* As in the tidyverse, variables in the dataframe can be referenced outside of quotation marks.

* The `:` character is used in `split_by()` to specify numeric boundaries (e.g. `0.009:0.013` means any number from 0.009 to 0.013 is acceptable for this level of the variable), and in and `control_for()` to specify tolerances (e.g. `-0.2:0.2` means controls will be acceptable if within ±0.2 of the match null).

* The `~` character is used in `split_by()` to specify different levels of an independent variable (e.g. `1.5:2.5 ~ 3.5:4.5 ~ 5.5:6.5` would specify three levels).
```
<br>

### Output {-}

Let's have a closer look at the first 5 rows of `stim`, which contains the output from above:

```{r, class='table', echo=FALSE}
stim %>%
  head(5) %>%
  knitr::kable()
```

<br>
We can see that we have 4 conditions:

* **A1_B1** (abstract, low probability)

* **A1_B2** (abstract, high probability)

* **A2_B1** (concrete, low probability)

* **A2_B2** (concrete, high probability)

<br>
Each row of the dataframe is controlled for in terms of frequency and length. The `match_null` variable tells us which condition stimuli were matched relative to. For instance, we can see that in row 3, items are matched relative to the word "relent". This means (for example) that all words for `item_nr` 3 are within ±0.2 Zipf of the Zipf value associated with the word snobby. By default, LexOPS will select the match_null for each item pseudo-randomly, such that each condition will be used as a match null an equal number of times, or as close to this ideal as is possible (e.g. the number of items requested may not be divisible by the number of conditions).

## Converting to Long Format

The table above shows the generated stimuli in wide format. This is a useful way to quickly view the stimuli and get a sense for what has been generated, but we often want to check our stimuli in more detail. The `long_format()` function is a quick way to convert stimuli generated in LexOPS into long format:

```{r, eval=FALSE}
stim_long <- long_format(stim)
```

Now we have the same stimuli in long format, with their associated values. Here are the same first 5 matched items from earlier, but in long format:

\small
```{r, class='table', echo=FALSE}
stim %>%
  long_format() %>%
  head(20) %>%
  knitr::kable()
```
\normalsize

Here we can see that indeed, the different conditions are within the boundaries we set, and that the variables used as controls are matched for items with the same `item_nr`.

## Plotting the Design

While having data in long format is undoubtably useful, it's not very efficient if you want to check what your stimuli look like in a quick glance (especially if your stimuli number in the thousands). What you probably want to do is plot the long format data to see how your stimuli differ between conditions and across matched items. Thankfully, LexOPS has a handy function to do exactly that:

```{r, fig.cap='The results of the `plot_design()` function for the generated stimuli.'}
plot_design(stim)
```

The distributions of all the numeric variables used as independent variables or controls are plotted for each condition (in a grey violin plot). The points depict the values of individual words, and points of the same colour (joined by lines) are matched items. As we'd expect, our example stimuli show the expected differences in Bigram Probability and Concreteness, while Frequency is matched closely, and Length is matched exactly.

## Generating as Many as Possible

Let's imagine that we're not entirely sure how many stimuli we could generate using our design. It may be that the `n = 25` [we used earlier](#generating-stimuli) is considerably fewer than the number of stimuli we could generate with no problems. One way to test this is to have LexOPS generate as many stimuli as possible. We can do this by setting `n = "all"`:

```{r, message=FALSE, results='hide'}
possible_stim <- LexOPS::lexops %>%
  subset(PK.Brysbaert >= 0.9) %>%
  split_by(CNC.Brysbaert, 1:2 ~ 4:5) %>%
  split_by(BG.SUBTLEX_UK, 0:0.003 ~ 0.009:0.013) %>%
  control_for(Length, 0:0) %>%
  control_for(Zipf.SUBTLEX_UK, -0.2:0.2) %>%
  generate(n = "all", match_null = "random")
```

This is much slower, as LexOPS will continue trying to generate combinations of words that fit the specified characteristics until it has exhausted all the possibilities. Nevertheless, we actually generated `r nrow(possible_stim)` words generated per condition. This number is likely to change slightly each time we run the pipeline, as different combinations are randomly made from all the possible combinations. That said, it *is* a fairly good indication of the number of possible stimuli we could generate.

The `r nrow(possible_stim)` words we've managed to generate per condition here is quite a bit higher than the 25 we originally generated. Does this mean we should just request a larger stimulus list, such as `n = 80`? Well, it depends. If we want as many stimuli as are possible, then it may make sense to just set `n = "all"`, but often we only want to use as many stimuli as we need to find our effect. Also, if we use as many combinations as possible, experimenters who want to replicate our effect using a different set of stimuli will likely have fewer novel combinations available to them.

```{block, type="danger"}
Note that when `n = "all"`, the default `match_null = "balanced"` is not recommended, as LexOPS will not know how many iterations will successfully generate items before the `generate()` function is actually run. LexOPS will give a warning if `n = "all"` and `match_null = "balanced"`, because the conditions selected as the match null will not actually be balanced in the generated stimuli.
```

It's also important to remember that when `n = "all"`, LexOPS will generate as many matched combinations of items, but will still generate different combinations each time the function is run.

## Plotting Iterations

It is also possible to check how well LexOPS performed when generating stimuli by plotting the cumulative item generation by iterations. To do this, we can use the `plot_iterations()` function. As an example, let's see how well we generated the stimuli in the last section.

```{r, fig.cap='The cumulative number of items generated per iteration.'}
plot_iterations(possible_stim)
```

This shows a characteristic levelling-off; iterations become increasingly less likely to successfully generate items as the pool of possible combinations is gradually exhausted.
